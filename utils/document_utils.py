import re
from docx import Document
import os
import uuid
from werkzeug.utils import secure_filename
from config.config import UPLOADS_DIR
from flask import session
from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline
model_name = "Davlan/bert-base-multilingual-cased-ner-hrl"  # h·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)
ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u ƒë∆∞·ªùng d·∫´n t√†i li·ªáu hi·ªán t·∫°i
doc_path = None

def load_document(doc_path):
    """
    T·∫£i n·ªôi dung t·ª´ t√†i li·ªáu docx
    """
    doc = Document(doc_path)
    return "\n".join([para.text.strip() for para in doc.paragraphs if para.text.strip()])


def clean_label(text):
    """
    L√†m s·∫°ch nh√£n ƒë·ªÉ tr√°nh nhi·ªÖu ƒë·∫ßu ra
    """
    text = re.sub(r"\[_\d+_\]", "", text)
    text = re.sub(r"[^\w\s√Ä-·ªπ]", "", text)
    text = text.strip()
    return text

def extract_fields(text,window_size=50):
    """
    Tr√≠ch xu·∫•t t√™n tr∆∞·ªùng ch√≠nh x√°c t·ª´ vƒÉn b·∫£n, t√°ch ph·∫ßn context th·∫≠t s·ª± g·∫ßn m√£ tr∆∞·ªùng nh·∫•t.
    """
    field_pattern = r"\[_\d+_\]|_{4,}|\.{4,}|\[fill\]"
    lines = text.splitlines()
    fields = []
    special_keywords = ["ng√†y", "th√°ng", "nƒÉm"]

    for i, line in enumerate(lines):
        matches = list(re.finditer(field_pattern, line))
        prev_match_end = 0

        for match in matches:
            field_code = match.group()
            match_start = match.start()
            match_end = match.end()

            # L·∫•y ƒëo·∫°n tr∆∞·ªõc m√£ tr∆∞·ªùng
            raw_context = line[prev_match_end:match_start].strip()
            prev_match_end = match_end

            # Fallback n·∫øu kh√¥ng c√≥ context
            if not raw_context and i > 0:
                raw_context = lines[i - 1].strip()

            # üëâ T√°ch c·ª•m cu·ªëi c√πng n·∫øu c√≥ d·∫•u ph·∫©y
            if "," in raw_context:
                context_segment = raw_context.split(",")[-1].strip()
            else:
                context_segment = raw_context

            cleaned_context = clean_label(context_segment)
            cleaned_context_lower = cleaned_context.lower()
            field_name = ""

            # N·∫øu l√† c·ª•m ng·∫Øn g·ªçn ‚Üí gi·ªØ nguy√™n
            if len(cleaned_context.split()) <= 4 and not re.search(r"[:\.\-]", cleaned_context):
                field_name = cleaned_context
            else:
                # ∆Øu ti√™n t·ª´ kh√≥a ƒë·∫∑c bi·ªát
                for kw in special_keywords:
                    if kw in cleaned_context_lower:
                        field_name = kw.capitalize()
                        break

                # N·∫øu kh√¥ng c√≥ t·ª´ kh√≥a, d√πng AI
                if not field_name:
                    limited_context = cleaned_context_lower[-window_size:]
                    label_text = ""
                    ner_results = ner_pipeline(limited_context)
                    for entity in ner_results:
                        if entity["entity_group"] in {"PER", "ORG", "LOC", "MISC"}:
                            label_text += entity["word"] + " "
                    if not label_text:
                        label_text = cleaned_context
                    field_name = label_text.strip()

            if field_name:
                fields.append({
                    "field_name": field_name,
                    "field_code": field_code
                })

    return fields


def upload_document(file):
    """
    X·ª≠ l√Ω t·∫£i l√™n t√†i li·ªáu v√† ki·ªÉm tra gi·ªõi h·∫°n upload c·ªßa ng∆∞·ªùi d√πng
    """
    global doc_path
    
    if file.filename == '':
        return {"error": "No selected file"}, 400
    
    if not file.filename.endswith('.docx'):
        return {"error": "Only DOCX files are allowed"}, 400
    
    # Ki·ªÉm tra gi·ªõi h·∫°n upload c·ªßa ng∆∞·ªùi d√πng
    from flask_login import current_user
    if current_user.is_authenticated:
        # Ki·ªÉm tra lo·∫°i g√≥i ƒëƒÉng k√Ω
        if current_user.subscription_type == 'free':
            # Ki·ªÉm tra s·ªë l·∫ßn upload c√≤n l·∫°i
            if current_user.free_downloads_left <= 0:
                return {"error": "B·∫°n ƒë√£ s·ª≠ d·ª•ng h·∫øt l∆∞·ª£t upload mi·ªÖn ph√≠. Vui l√≤ng n√¢ng c·∫•p l√™n g√≥i VIP ƒë·ªÉ ti·∫øp t·ª•c s·ª≠ d·ª•ng.", "upgrade_required": True}, 403
            
            # Gi·∫£m s·ªë l·∫ßn upload c√≤n l·∫°i
            from models.user import db
            current_user.free_downloads_left -= 1
            db.session.commit()
        elif current_user.subscription_type == 'standard':
            # Ki·ªÉm tra s·ªë l·∫ßn upload trong th√°ng
            if current_user.monthly_download_count >= 100:
                return {"error": "B·∫°n ƒë√£ s·ª≠ d·ª•ng h·∫øt 100 l∆∞·ª£t upload trong th√°ng. Vui l√≤ng n√¢ng c·∫•p l√™n g√≥i VIP ƒë·ªÉ kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn upload.", "upgrade_required": True}, 403
            
            # TƒÉng s·ªë l·∫ßn upload trong th√°ng
            from models.user import db
            current_user.monthly_download_count += 1
            db.session.commit()
        # G√≥i VIP kh√¥ng gi·ªõi h·∫°n s·ªë l·∫ßn upload
    
    filename = secure_filename(str(uuid.uuid4()) + '_' + file.filename)
    filepath = os.path.join(UPLOADS_DIR, filename)
    file.save(filepath)
    
    # L∆∞u ƒë∆∞·ªùng d·∫´n v√†o c·∫£ session v√† bi·∫øn to√†n c·ª•c
    set_doc_path(filepath)
    
    # X√°c ƒë·ªãnh lo·∫°i bi·ªÉu m·∫´u
    from utils.form_type_detector import FormTypeDetector
    detector = FormTypeDetector()
    form_type = detector.detect_form_type(filepath)
    
    # Tr·∫£ v·ªÅ th√¥ng tin v·ªÅ s·ªë l·∫ßn upload c√≤n l·∫°i n·∫øu l√† g√≥i mi·ªÖn ph√≠
    if current_user.is_authenticated and current_user.subscription_type == 'free':
        return {
            "message": "File uploaded successfully", 
            "filename": filename,
            "free_downloads_left": current_user.free_downloads_left,
            "form_type": form_type
        }, 200
    
    return {"message": "File uploaded successfully", "filename": filename, "form_type": form_type}, 200

def get_doc_path():
    """
    Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n t√†i li·ªáu hi·ªán t·∫°i t·ª´ session ho·∫∑c bi·∫øn to√†n c·ª•c
    """
    try:
        # ∆Øu ti√™n l·∫•y t·ª´ session n·∫øu c√≥
        if 'doc_path' in session:
            return session['doc_path']
        return doc_path
    except Exception as e:
        print(f"Error in get_doc_path: {str(e)}")
        return doc_path

def set_doc_path(path):
    """
    Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n t√†i li·ªáu hi·ªán t·∫°i v√†o session v√† bi·∫øn to√†n c·ª•c
    """
    global doc_path
    try:
        # L∆∞u v√†o c·∫£ session v√† bi·∫øn to√†n c·ª•c
        session['doc_path'] = path
    except Exception as e:
        print(f"Error setting doc_path in session: {str(e)}")
    # V·∫´n l∆∞u v√†o bi·∫øn to√†n c·ª•c ƒë·ªÉ ƒë·∫£m b·∫£o t∆∞∆°ng th√≠ch ng∆∞·ª£c
    doc_path = path
def extract_table_fields(doc_path,window_size=40): 
    """
    Tr√≠ch xu·∫•t c√°c tr∆∞·ªùng t·ª´ b·∫£ng v·ªõi ƒë·ªô ch√≠nh x√°c cao h∆°n, tr√°nh r√∫t ng·∫Øn nh√£n sai l·ªách.
    """
    doc = Document(doc_path)
    fields = []

    field_patterns = [r"\[_\d+_\]", r"\.{4,}", r"_{4,}", r"\[fill\]"]
    special_keywords = ["ng√†y", "th√°ng", "nƒÉm"]

    for table in doc.tables:
        for row in table.rows:
            if len(row.cells) >= 2:
                raw_label = row.cells[0].text.strip()
                field_value = row.cells[1].text.strip()

                for pattern in field_patterns:
                    match = re.search(pattern, field_value)
                    if match:
                        field_code = match.group()
                        field_name = ""

                        cleaned_label = clean_label(raw_label)
                        cleaned_label_lower = cleaned_label.lower()

                        # N·∫øu nh√£n ng·∫Øn g·ªçn, kh√¥ng ch·ª©a k√Ω t·ª± g√¢y nhi·ªÖu ‚Üí gi·ªØ nguy√™n
                        if len(cleaned_label.split()) <= 4 and not re.search(r"[:\.\-]", cleaned_label):
                            field_name = cleaned_label
                        else:
                            # ∆Øu ti√™n t·ª´ kh√≥a ƒë·∫∑c bi·ªát
                            for kw in special_keywords:
                                if kw in cleaned_label_lower:
                                    field_name = kw.capitalize()
                                    break

                            # N·∫øu v·∫´n ch∆∞a c√≥, d√πng AI
                            if not field_name:
                                label_text = ""
                                limited_context = cleaned_label_lower[-window_size:]
                                ner_results = ner_pipeline(limited_context)
                                for entity in ner_results:
                                    if entity["entity_group"] in {"PER", "ORG", "LOC", "MISC"}:
                                        label_text += entity["word"] + " "
                                if not label_text:
                                    label_text = cleaned_label
                                field_name = label_text.strip()

                        if field_name:
                            fields.append({
                                "field_name": field_name.strip(),
                                "field_code": field_code
                            })
                        break

    return fields

def extract_all_fields(doc_path):
    """
    Tr√≠ch xu·∫•t t·∫•t c·∫£ c√°c tr∆∞·ªùng t·ª´ t√†i li·ªáu (bao g·ªìm vƒÉn b·∫£n v√† b·∫£ng),
    s·∫Øp x·∫øp t·ª´ tr√™n xu·ªëng d∆∞·ªõi v√† lo·∫°i b·ªè c√°c tr∆∞·ªùng tr√πng l·∫∑p d·ª±a tr√™n `field_code`.
    """
    # Tr√≠ch xu·∫•t t·ª´ vƒÉn b·∫£n v√† b·∫£ng
    text = load_document(doc_path)
    text_fields = extract_fields(text)
    table_fields = extract_table_fields(doc_path)
    
    # G·ªôp t·∫•t c·∫£ c√°c tr∆∞·ªùng l·∫°i
    all_fields = text_fields + table_fields

    # S·∫Øp x·∫øp t·ª´ tr√™n xu·ªëng d∆∞·ªõi (gi·∫£ s·ª≠ c√≥ key 'y' bi·ªÉu th·ªã v·ªã tr√≠ theo chi·ªÅu d·ªçc)
    all_fields.sort(key=lambda field: field.get("y", 0))  # b·∫°n c√≥ th·ªÉ thay "y" b·∫±ng "position" hay t√™n key ph√π h·ª£p

    # Lo·∫°i b·ªè tr√πng l·∫∑p d·ª±a tr√™n `field_code`
    combined_fields = []
    seen_codes = set()

    for field in all_fields:
        code = field["field_code"]
        if code not in seen_codes:
            combined_fields.append(field)
            seen_codes.add(code)

    return combined_fields